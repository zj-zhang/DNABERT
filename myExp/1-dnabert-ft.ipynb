{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d19f31",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc04d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run run_finetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9251c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_finetune.py --model_type dna --tokenizer_name=dna6 --model_name_or_path /mnt/ceph/users/zzhang/DNABERT/myExp/6-new-12w-0 --task_name dnaprom --do_train --do_eval --data_dir ./sample_data/ft/6 --max_seq_length 100 --per_gpu_eval_batch_size=32 --per_gpu_train_batch_size=32 --learning_rate 2e-4 --num_train_epochs 5.0 --output_dir ./outputs/test_ft_6 --evaluate_during_training --logging_steps 100 --save_steps 4000 --warmup_percent 0.1 --hidden_dropout_prob 0.1 --overwrite_output --weight_decay 0.01 --n_process 8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "\n",
    "cmd_str = \"\"\"run_finetune.py \n",
    "--model_type dna \n",
    "--tokenizer_name=dna6    \n",
    "--model_name_or_path /mnt/ceph/users/zzhang/DNABERT/myExp/6-new-12w-0     \n",
    "--task_name dnaprom     \n",
    "--do_train     \n",
    "--do_eval     \n",
    "--data_dir ./sample_data/ft/6     \n",
    "--max_seq_length 100     \n",
    "--per_gpu_eval_batch_size=32       \n",
    "--per_gpu_train_batch_size=32       \n",
    "--learning_rate 2e-4     \n",
    "--num_train_epochs 5.0     \n",
    "--output_dir ./outputs/test_ft_6   \n",
    "--evaluate_during_training     \n",
    "--logging_steps 100     \n",
    "--save_steps 4000     \n",
    "--warmup_percent 0.1     \n",
    "--hidden_dropout_prob 0.1     \n",
    "--overwrite_output     \n",
    "--weight_decay 0.01     \n",
    "--n_process 8\n",
    "\"\"\"\n",
    "\n",
    "arg_list = cmd_str.split()\n",
    "sys.argv = arg_list\n",
    "print(\"python \" + \" \".join(cmd_str.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb7277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='./sample_data/ft/6', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0002, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=100, max_steps=-1, model_name_or_path='/mnt/ceph/users/zzhang/DNABERT/myExp/6-new-12w-0', model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=5.0, output_dir='./outputs/test_ft_6', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=32, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "set_seed(args)\n",
    "\n",
    "# Prepare GLUE task\n",
    "args.task_name = args.task_name.lower()\n",
    "if args.task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "processor = processors[args.task_name]()\n",
    "args.output_mode = output_modes[args.task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695cd25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0', '1'],\n",
       " {'cola': 'classification',\n",
       "  'mnli': 'classification',\n",
       "  'mnli-mm': 'classification',\n",
       "  'mrpc': 'classification',\n",
       "  'sst-2': 'classification',\n",
       "  'sts-b': 'regression',\n",
       "  'qqp': 'classification',\n",
       "  'qnli': 'classification',\n",
       "  'rte': 'classification',\n",
       "  'wnli': 'classification',\n",
       "  'dnaprom': 'classification',\n",
       "  'dna690': 'classification',\n",
       "  'dnapair': 'classification',\n",
       "  'dnasplice': 'classification'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list, output_modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20080d",
   "metadata": {},
   "source": [
    "# 2. Get DNABERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbff1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# FZZ: get model from MODEL_CLASSES\n",
    "args.model_type = args.model_type.lower()\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "\n",
    "config = config_class.from_pretrained(\n",
    "    args.config_name if args.config_name else args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=args.task_name,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")\n",
    "\n",
    "config.hidden_dropout_prob = args.hidden_dropout_prob\n",
    "config.attention_probs_dropout_prob = args.attention_probs_dropout_prob\n",
    "if args.model_type in [\"dnalong\", \"dnalongcat\"]:\n",
    "    assert args.max_seq_length % 512 == 0\n",
    "config.split = int(args.max_seq_length/512)\n",
    "config.rnn = args.rnn\n",
    "config.num_rnn_layer = args.num_rnn_layer\n",
    "config.rnn_dropout = args.rnn_dropout\n",
    "config.rnn_hidden = args.rnn_hidden\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "    do_lower_case=args.do_lower_case,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")\n",
    "model = model_class.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7665d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main workhorse for fine-tuning classification/regression tasks\n",
    "?model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f474bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_data/ft/6\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "print(args.data_dir)\n",
    "train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b26141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datasets to torch.DataSet\n",
    "args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7e246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch from `torch.DataLoader`\n",
    "batch = next(iter(train_dataloader))\n",
    "inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff3f910",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.6802, grad_fn=<NllLossBackward>),\n",
       " tensor([[ 0.2693, -0.0378],\n",
       "         [ 0.4302,  0.5268],\n",
       "         [ 0.1384, -0.0703],\n",
       "         [ 0.2343, -0.0050],\n",
       "         [ 0.1529, -0.1760]], grad_fn=<SliceBackward>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs is tuple of (Loss, Logits)\n",
    "outputs = model(**inputs)\n",
    "print(len(outputs))\n",
    "[outputs[0], outputs[1][0:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbca5e",
   "metadata": {},
   "source": [
    "# 3. Features are embedded prior in `load_and_cache_examples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c238be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"guid\": \"train-1\",\n",
       "  \"label\": \"0\",\n",
       "  \"text_a\": \"CACAGC ACAGCC CAGCCA AGCCAG GCCAGC CCAGCC CAGCCA AGCCAC GCCACT CCACTA CACTAG ACTAGG CTAGGC TAGGCC AGGCCC GGCCCT GCCCTG CCCTGT CCTGTC CTGTCC TGTCCT GTCCTG TCCTGC CCTGCA CTGCAG TGCAGC GCAGCC CAGCCC AGCCCC GCCCCC CCCCCT CCCCTG CCCTGT CCTGTA CTGTAG TGTAGG GTAGGG TAGGGG AGGGGT GGGGTC GGGTCT GGTCTG GTCTGG TCTGGA CTGGAA TGGAAC GGAACA GAACAG AACAGC ACAGCC CAGCCA AGCCAG GCCAGG CCAGGA CAGGAG AGGAGT GGAGTG GAGTGG AGTGGT GTGGTT TGGTTT GGTTTA GTTTAA TTTAAG TTAAGA TAAGAG AAGAGG AGAGGC GAGGCA AGGCAG GGCAGG GCAGGG CAGGGG AGGGGA GGGGAG GGGAGT GGAGTC GAGTCG AGTCGC GTCGCC TCGCCT CGCCTT GCCTTG CCTTGC CTTGCC TTGCCC TGCCCT GCCCTG CCCTGT CCTGTG CTGTGC TGTGCC GTGCCA TGCCAC GCCACA CCACAC\",\n",
       "  \"text_b\": null\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = processor.get_train_examples(args.data_dir)\n",
    "print(len(examples))\n",
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea3ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = args.max_seq_length\n",
    "pad_on_left = bool(args.model_type in [\"xlnet\"])\n",
    "pad_token = tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
    "pad_token_segment_id = 4 if args.model_type in [\"xlnet\"] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b66176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n"
     ]
    }
   ],
   "source": [
    "output_mode = output_modes[args.task_name]\n",
    "print(output_mode)\n",
    "features = convert_examples_to_features(\n",
    "    examples,\n",
    "    tokenizer,\n",
    "    label_list=label_list,\n",
    "    max_length=max_length,\n",
    "    output_mode=output_mode,\n",
    "    pad_on_left=pad_on_left,  # pad on the left for xlnet\n",
    "    pad_token=pad_token,\n",
    "    pad_token_segment_id=pad_token_segment_id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224a0314",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features  32366\n",
      "examples  32366\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(\"features \", len(features))\n",
    "print(\"examples \", len(examples))\n",
    "print(len(features[0].attention_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd911aa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"do_sample\": false,\n",
       "  \"eos_token_ids\": 0,\n",
       "  \"finetuning_task\": \"dnaprom\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"is_decoder\": false,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"length_penalty\": 1.0,\n",
       "  \"max_length\": 20,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_beams\": 1,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"num_return_sequences\": 1,\n",
       "  \"num_rnn_layer\": 2,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pruned_heads\": {},\n",
       "  \"repetition_penalty\": 1.0,\n",
       "  \"rnn\": \"lstm\",\n",
       "  \"rnn_dropout\": 0.0,\n",
       "  \"rnn_hidden\": 768,\n",
       "  \"split\": 0,\n",
       "  \"temperature\": 1.0,\n",
       "  \"top_k\": 50,\n",
       "  \"top_p\": 1.0,\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 4101\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501afda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
